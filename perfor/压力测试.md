# 压力测试

以一次测试环境的压力测试为例，说明压力测试的流程和注意事项。

本次的主体识别的功能主要是```cpu密集型```，部署环境是```k8s```，所以关注点主要在pod的数量和进程数。

## 压测工具

现有的压测工具琳琅满目，主要有：[Apache JMeter JMeter](https://github.com/apache/jmeter), [Loadrunner](https://www.microfocus.com/zh-cn/products/loadrunner-load-testing/overview)等。我们这里选取了免费开源的JMeter。网上有很多相应的教程，这里就不做过多的叙述了。

## 测试过程

* 配置好测试请求

    基于业务的需求，在测试的前期阶段配置了10个线程、请求url和参数、汇总报告等。

* 测试遇到的问题

    部署在本地的应用的tps可以随着虚拟机的cpu的增长而增长。由于需要运行TensorFlow，当然内存的分配也是充裕的。同时在cpu充裕的环境下，开启多进程的也是能测试到tps的类线性增长。这是符合我们的直观感受的。然而，当我们部署到k8s环境中时，开启一个pod和多个pod的tps都是2个/s，这个就明显不符合预期了。

    那么，这问题出现在哪里呢？

* 排查问题

    1. 首先排查的是镜像更新问题，因为k8s的拉取策略与多种。

        是最新的

    2. cpu和内存问题

        通过dashboard监控得知集群的cpu和内存都是充裕的，并且在部署文件中并没有限制其大小(当然这是不对的，生产环境中最好对其设定limit限制)。只有pod所在节点的cpu的主频稍稍比本地的低一点，所以问题不在cpu和内存上。

    3. io问题

        在对程序进行压测的的时候，io是一个必须考虑的问题。io的类型包括：文件读写io，网络io等。在开头已经说明了，这是一个cpu密集型的应用，而且处理请求的函数也是异步实现的。排查了程序本身的情况和在本地测试的情况后就可以大致定位到```瓶颈出现在网络io```。

        恰好，这时候```连接到服务的ssh窗口出现了卡顿```。明显的是本地网络带宽过载了或者是当前网络不稳定。

* 解决问题

    经过对服务资源问题的排查。我们可以比较肯定是本地网络出现了过载。那么需要经过最终的确认，然后针对性的解决问题。

    当打资源管理器时发现，上传速率一直在5M/s，本地的是100M的光线。上传速率明显超载了。然后停止jemeter后发现，ssh不再卡顿。因为测试发送的是图片，所以才会占用这么大的带宽。

    最后，在集群中的某一台空闲的节点中利用```jemeter命令行```进行测试发现，tps较好的拟合了本地的测试结果。至此，整个tps压测流程完毕。

## 结语

在进行压力测试时，需要充分考虑包括cpu、内存、io等在内的所有情况。同时有些时候测试过程中遇到的瓶颈不一定在服务端，还有可能在客户端，本文遇到的情况就是如此。

之前读过两本本比较实用的书：```Wireshark网络分析就这么简单```和```Wireshark网络分析的艺术```，里面就有类似的一个例子：一个困扰了整个团队半个月的网络测试问题，最终发现是用于测试的windows笔记本的操作系统是用一个镜像安装的，里面缺少了某些文件。
